{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5024,"status":"ok","timestamp":1679709082221,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"ks2E7MR7cCh5","outputId":"a46cda7e-1a73-435f-b94f-1b2973c627e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":509,"status":"ok","timestamp":1679709087744,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"tnSYHdoKcLBq","outputId":"84e1868f-2fdf-4687-cf03-03de7265d91d"},"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/CRAFT-OCR\n"]}],"source":["%cd /gdrive/MyDrive/CRAFT-OCR/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":612,"status":"ok","timestamp":1676444037146,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"OPTsUV-Nswn_","outputId":"eefda0cc-b93e-43f8-85aa-14d598d5d18f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch\n"]}],"source":["%cd CRAFT-pytorch/"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"kvRYXHBKwr9r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679709193288,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"}},"outputId":"13a49169-a82e-4660-8e51-d28118bf3f93"},"outputs":[{"output_type":"stream","name":"stdout","text":["CRAFT-pytorch  deep-text-recognition-benchmark\tpipeline.py  Result  test\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42097,"status":"ok","timestamp":1676198927902,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"PcwE21ebvaLw","outputId":"9383cbd9-46ea-4a08-c2cb-3a0495f3cc61"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Loading weights from checkpoint (/gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/craft_mlt_25k.pth)\n","elapsed time : 27.3226318359375s\n"]}],"source":["!python pipeline.py --trained_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/craft_mlt_25k.pth --test_folder /gdrive/MyDrive/CRAFT-OCR/test --cuda false"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":688,"status":"ok","timestamp":1675318686330,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"YS-fxYYaxioA","outputId":"23271097-a142-487f-9017-9d705c41fcf2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch\n"]}],"source":["%cd /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400605,"status":"ok","timestamp":1675319200178,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"S9_UfT8cxYiZ","outputId":"db1a3f91-8666-493d-f640-42f13f2383f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Loading weights from checkpoint (/gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/craft_mlt_25k.pth)\n","elapsed time : 394.67581367492676s\n"]}],"source":["!python test.py --trained_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/craft_mlt_25k.pth --test_folder /gdrive/MyDrive/CRAFT-OCR/test --cuda false"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1612,"status":"ok","timestamp":1676198954111,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"Zg3IXY2xvb7O","outputId":"fc8a3170-c52c-416f-87ee-d6a7b98d52be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Image saved to /content/Pipeline/Crop_Words/test-now_1049.3438_29.981245_1326.6703_29.981245_1326.6703_77.451546_1049.3438_77.451546.jpg\n","Image saved to /content/Pipeline/Crop_Words/test-now_1341.6608_29.981245_1476.5764_29.981245_1476.5764_77.451546_1341.6608_77.451546.jpg\n","Image saved to /content/Pipeline/Crop_Words/test-now_1501.5609_29.98125_1566.5203_29.98125_1566.5203_77.45156_1501.5609_77.45156.jpg\n","Image saved to /content/Pipeline/Crop_Words/test-now_542.16095_139.9125_604.6219_139.9125_604.6219_164.89688_542.16095_164.89688.jpg\n","Image saved to /content/Pipeline/Crop_Words/test-now_1229.2312_194.87813_1334.1656_194.87813_1334.1656_222.36093_1229.2312_222.36093.jpg\n","Image saved to /content/Pipeline/Crop_Words/test-now_32.479687_801.9984_177.38907_801.9984_177.38907_861.96094_32.479687_861.96094.jpg\n","Image saved to /content/Pipeline/Crop_Words/test-now_189.88126_806.9953_224.85938_806.9953_224.85938_856.96405_189.88126_856.96405.jpg\n"]}],"source":["!python crop_image.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":504,"status":"ok","timestamp":1674667613335,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"YOpNWQYR9j5m","outputId":"0f21b519-8963-4f85-f53c-411511ed892a"},"outputs":[{"name":"stdout","output_type":"stream","text":[" basenet\t     Resultsres_Cars0.jpg\n"," craft_mlt_25k.pth   Resultsres_Cars0.txt\n"," craft.py\t     Resultsres_Cars1.jpg\n"," craft_utils.py      Resultsres_Cars1.txt\n"," crop_image.py\t     Resultsres_Cars2.jpg\n"," CSV_result\t     Resultsres_Cars2.txt\n"," figures\t     Resultsres_Cars3.jpg\n"," file_utils.py\t     Resultsres_Cars3.txt\n"," imgproc.py\t     Resultsres_Cars4.jpg\n"," LICENSE\t     Resultsres_Cars4.txt\n"," pipeline.py\t     Resultsres_Cars5.jpg\n"," __pycache__\t     Resultsres_Cars5.txt\n"," README.md\t     Resultsres_Cars6.jpg\n"," refinenet.py\t     Resultsres_Cars6.txt\n"," requirements.txt   'Resultsres_Deutscher_Personalausweis_(2021_Version).jpg'\n"," result\t\t    'Resultsres_Deutscher_Personalausweis_(2021_Version).txt'\n"," Results\t     test.py\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5734,"status":"ok","timestamp":1676199019424,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"Fl9WSnpg9mJF","outputId":"36eec608-f0c4-4605-a109-fd7694e49241"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","No Transformation module specified\n","model input parameters 32 100 20 1 512 256 37 25 None VGG BiLSTM CTC\n","loading pretrained model from /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-VGG-BiLSTM-CTC.pth\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","--------------------------------------------------------------------------------\n","image_path               \t predicted_labels         \t confidence score\n","--------------------------------------------------------------------------------\n","e-what.png               \t lts                      \t 0.0001\n","test-now_32.479687_801.9984_177.38907_801.9984_177.38907_861.96094_32.479687_861.96094.jpg\t cam                      \t 0.9657\n","test-now_189.88126_806.9953_224.85938_806.9953_224.85938_856.96405_189.88126_856.96405.jpg\t ip                       \t 0.0276\n","test-now_542.16095_139.9125_604.6219_139.9125_604.6219_164.89688_542.16095_164.89688.jpg\t massive                  \t 0.6304\n","test-now_1049.3438_29.981245_1326.6703_29.981245_1326.6703_77.451546_1049.3438_77.451546.jpg\t 12022028                 \t 0.1524\n","test-now_1229.2312_194.87813_1334.1656_194.87813_1334.1656_222.36093_1229.2312_222.36093.jpg\t autojagency              \t 0.4213\n","test-now_1341.6608_29.981245_1476.5764_29.981245_1476.5764_77.451546_1341.6608_77.451546.jpg\t 0411                     \t 0.3086\n","test-now_1501.5609_29.98125_1566.5203_29.98125_1566.5203_77.45156_1501.5609_77.45156.jpg\t 12                       \t 0.7841\n"]}],"source":["!python /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/demo.py --Transformation None --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction CTC --image_folder /content/Pipeline/Crop_Words --saved_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-VGG-BiLSTM-CTC.pth"]},{"cell_type":"markdown","metadata":{"id":"8W6kzL4IZEoN"},"source":["## Test Again"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10426,"status":"ok","timestamp":1674676970863,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"E61iUhI6ZEVO","outputId":"2671ee5a-acf5-467b-a15c-4fcc7536612f"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:252: UserWarning: Accessing the model URLs via the internal dictionary of the module is deprecated since 0.13 and may be removed in the future. Please access them via the appropriate Weights Enum instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Loading weights from checkpoint (/gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/craft_mlt_25k.pth)\n","elapsed time : 2.574652671813965s\n"]}],"source":["!python pipeline.py --trained_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/craft_mlt_25k.pth --test_folder /gdrive/MyDrive/CRAFT-OCR/test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1355,"status":"ok","timestamp":1674677004654,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"BgNcAtDXJDUF","outputId":"4e41756a-6a41-479f-d234-37eb579c7d4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Image saved to /content/Pipeline/Crop_Words/Cars4.pn_182.02478_100.03222_373.94797_125.065674_362.87732_209.9405_170.95415_184.90706.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars4.pn_387.09213_137.8075_500.64566_149.97395_493.15512_219.8857_379.60156_207.71924.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars6.pn_165.60605_146.12186_363.4546_150.42291_362.11368_212.10388_164.26515_207.80284.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars6.pn_184.11198_208.28267_304.3323_210.3918_303.91797_234.01025_183.69763_231.90112.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars6.pn_133.33333_213.33333_162.66667_213.33333_162.66667_230.66667_133.33333_230.66667.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars6.pn_332.0_220.0_356.0_220.0_356.0_234.66667_332.0_234.66667.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars3.pn_153.33333_129.33333_201.33333_129.33333_201.33333_153.33333_153.33333_153.33333.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars3.pn_204.0_130.66667_248.0_130.66667_248.0_154.66667_204.0_154.66667.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars5.pn_34.803_271.39456_79.17042_273.2432_78.48411_289.71457_34.11669_287.86594.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars5.pn_118.666664_272.0_158.66667_272.0_158.66667_289.33334_118.666664_289.33334.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars5.pn_80.0_273.33334_117.333336_273.33334_117.333336_288.0_80.0_288.0.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars5.pn_361.33334_274.66666_384.0_274.66666_384.0_281.33334_361.33334_281.33334.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars11.pn_133.33333_204.0_194.66667_204.0_194.66667_234.66667_133.33333_234.66667.jpg\n","Image saved to /content/Pipeline/Crop_Words/Cars11.pn_201.33333_204.0_269.33334_204.0_269.33334_234.66667_201.33333_234.66667.jpg\n","Image saved to /content/Pipeline/Crop_Words/indane.pn_5.2866654_5.1836257_133.85732_-2.1632805_135.56494_27.720093_6.994293_35.067.jpg\n"]}],"source":["!python crop_image.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3922,"status":"ok","timestamp":1675316723130,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"tSlS2AL9bGBC","outputId":"4bbce7a9-a95b-4776-c2f4-03f56137fcb0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/demo.py\", line 12, in <module>\n","    from model import Model\n","  File \"/gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/model.py\", line 22, in <module>\n","    from modules.prediction import Attention\n","  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 844, in exec_module\n","  File \"<frozen importlib._bootstrap_external>\", line 939, in get_code\n","  File \"<frozen importlib._bootstrap_external>\", line 1038, in get_data\n","KeyboardInterrupt\n","^C\n"]}],"source":["!python /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/demo.py --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn --image_folder /content/Pipeline/Crop_Words --saved_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-VGG-BiLSTM-CTC.pth"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679709210169,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"0tizdICRqWuC","outputId":"a37c4169-a633-4137-9024-8e53ff6974b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark\n"]}],"source":["%cd /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":318358,"status":"ok","timestamp":1675317349731,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"tbGzjB6bh0e4","outputId":"33d6758d-7c75-493e-90be-b8c0ed817abe"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","No Transformation module specified\n","model input parameters 32 100 20 1 512 256 37 25 None VGG BiLSTM CTC\n","loading pretrained model from /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-VGG-BiLSTM-CTC.pth\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IIIT5k_3000\t dataset: /\n","sub-directory:\t/.\t num samples: 3000\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Acc 82.633\t normalized_ED 0.940\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/SVT\t dataset: /\n","sub-directory:\t/.\t num samples: 647\n","Acc 82.071\t normalized_ED 0.927\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC03_860\t dataset: /\n","sub-directory:\t/.\t num samples: 860\n","Acc 92.791\t normalized_ED 0.975\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC03_867\t dataset: /\n","sub-directory:\t/.\t num samples: 867\n","Acc 92.964\t normalized_ED 0.974\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC13_857\t dataset: /\n","sub-directory:\t/.\t num samples: 857\n","Acc 90.548\t normalized_ED 0.972\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC13_1015\t dataset: /\n","sub-directory:\t/.\t num samples: 1015\n","Acc 88.867\t normalized_ED 0.952\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC15_1811\t dataset: /\n","sub-directory:\t/.\t num samples: 1811\n","Acc 68.857\t normalized_ED 0.877\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC15_2077\t dataset: /\n","sub-directory:\t/.\t num samples: 1922\n","Acc 66.285\t normalized_ED 0.846\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/SVTP\t dataset: /\n","sub-directory:\t/.\t num samples: 645\n","Acc 71.008\t normalized_ED 0.885\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/CUTE80\t dataset: /\n","sub-directory:\t/.\t num samples: 287\n","Acc 62.369\t normalized_ED 0.822\n","--------------------------------------------------------------------------------\n","accuracy: IIIT5k_3000: 82.633\tSVT: 82.071\tIC03_860: 92.791\tIC03_867: 92.964\tIC13_857: 90.548\tIC13_1015: 88.867\tIC15_1811: 68.857\tIC15_2077: 66.285\tSVTP: 71.008\tCUTE80: 62.369\ttotal_accuracy: 79.338\taveraged_infer_time: 24.064\t# parameters: 8.452\n"]}],"source":["!python3 test.py --eval_data /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation --benchmark_all_eval --Transformation None --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction CTC --saved_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-VGG-BiLSTM-CTC.pth"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Awb9h6XrpCgG","outputId":"54cebf0b-9581-4e3c-bc4d-8f19494bcc4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n","loading pretrained model from /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/TPS-ResNet-BiLSTM-Attn.pth\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IIIT5k_3000\t dataset: /\n","sub-directory:\t/.\t num samples: 3000\n","/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","Acc 87.367\t normalized_ED 0.959\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/SVT\t dataset: /\n","sub-directory:\t/.\t num samples: 647\n","Acc 87.326\t normalized_ED 0.954\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC03_860\t dataset: /\n","sub-directory:\t/.\t num samples: 860\n","Acc 95.116\t normalized_ED 0.982\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC03_867\t dataset: /\n","sub-directory:\t/.\t num samples: 867\n","Acc 94.694\t normalized_ED 0.980\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC13_857\t dataset: /\n","sub-directory:\t/.\t num samples: 857\n","Acc 92.999\t normalized_ED 0.979\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC13_1015\t dataset: /\n","sub-directory:\t/.\t num samples: 1015\n","Acc 92.217\t normalized_ED 0.967\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC15_1811\t dataset: /\n","sub-directory:\t/.\t num samples: 1811\n","Acc 78.244\t normalized_ED 0.916\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/IC15_2077\t dataset: /\n","sub-directory:\t/.\t num samples: 1922\n","Acc 75.390\t normalized_ED 0.885\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/SVTP\t dataset: /\n","sub-directory:\t/.\t num samples: 645\n","Acc 80.155\t normalized_ED 0.915\n","--------------------------------------------------------------------------------\n","dataset_root:    /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation/CUTE80\t dataset: /\n","sub-directory:\t/.\t num samples: 287\n","Acc 74.216\t normalized_ED 0.880\n","--------------------------------------------------------------------------------\n","accuracy: IIIT5k_3000: 87.367\tSVT: 87.326\tIC03_860: 95.116\tIC03_867: 94.694\tIC13_857: 92.999\tIC13_1015: 92.217\tIC15_1811: 78.244\tIC15_2077: 75.390\tSVTP: 80.155\tCUTE80: 74.216\ttotal_accuracy: 85.249\taveraged_infer_time: 219.389\t# parameters: 49.555\n"]}],"source":["!python3 test.py --eval_data /gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/data_lmdb_release/evaluation --benchmark_all_eval --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn --saved_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/TPS-ResNet-BiLSTM-Attn.pth"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7572,"status":"ok","timestamp":1679719949272,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"-tyrBkeP2gHh","outputId":"286f6e61-cc16-49d1-c486-0182ccb342d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n","loading pretrained model from /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/TPS-ResNet-BiLSTM-Attn.pth\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","--------------------------------------------------------------------------------\n","image_path               \t predicted_labels         \t confidence score\n","--------------------------------------------------------------------------------\n","Cars2.png                \t preanip                  \t 0.0344\n","Cars2_Super_Resolution.jpg\t preatip                  \t 0.0820\n","Cars18.png               \t m666y00                  \t 0.0690\n","Cars181.png              \t juhithad                 \t 0.0298\n","Cars181_Super_Resolution.jpg\t whithad                  \t 0.0781\n","Cars183.png              \t britooot                 \t 0.1843\n","Cars186.png              \t b26spfa                  \t 0.0400\n","Cars190.png              \t kle4a2670                \t 0.2345\n","Cars197.png              \t alr33tee                 \t 0.1204\n","Cars200.png              \t kangabor                 \t 0.0001\n","Cars201.png              \t blr33tee                 \t 0.0391\n","Cars202.png              \t kwid                     \t 0.9889\n","file_Cars11.jpg          \t worsigk                  \t 0.3511\n"]}],"source":["!python3 demo.py --Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn --image_folder demo_image/ --saved_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/TPS-ResNet-BiLSTM-Attn.pth"]},{"cell_type":"code","source":["!python3 demo.py --Transformation None --FeatureExtraction ResNet --SequenceModeling None --Prediction CTC --image_folder demo_image/ --saved_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-ResNet-None-CTC.pth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Mh5SVus9pKp","executionInfo":{"status":"ok","timestamp":1679719764407,"user_tz":-330,"elapsed":8164,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"}},"outputId":"49d7507f-51a5-465a-b772-6dec9b0fda8c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","No Transformation module specified\n","No SequenceModeling module specified\n","model input parameters 32 100 20 1 512 256 37 25 None ResNet None CTC\n","loading pretrained model from /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-ResNet-None-CTC.pth\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","--------------------------------------------------------------------------------\n","image_path               \t predicted_labels         \t confidence score\n","--------------------------------------------------------------------------------\n","Cars0.png                \t a                        \t 0.0882\n","Cars2.png                \t preanh                   \t 0.0261\n","Cars2_Super_Resolution.jpg\t preate                   \t 0.0029\n","Cars18.png               \t mog6yob                  \t 0.0274\n","Cars20.png               \t ad                       \t 0.0022\n","Cars21.png               \t lirol                    \t 0.0021\n","Cars21_Super_Resolution.jpg\t liro                     \t 0.0001\n","Cars181.png              \t waicad                   \t 0.0103\n","Cars181_Super_Resolution.jpg\t pcaon                    \t 0.0002\n","Cars183.png              \t libritooon               \t 0.0216\n","Cars186.png              \t b26spea                  \t 0.0459\n","Cars190.png              \t kle442670                \t 0.0301\n","Cars193.png              \t beovem                   \t 0.0006\n","Cars196.png              \t t                        \t 0.0019\n","Cars197.png              \t ar33tee                  \t 0.1426\n","Cars199.png              \t emho1ae8017              \t 0.0279\n","Cars200.png              \t maotabatison             \t 0.0000\n","Cars201.png              \t lr33tee                  \t 0.1282\n","Cars202.png              \t lkwid                    \t 0.0524\n","Cars206.png              \t hnn                      \t 0.0000\n","file_Cars11.jpg          \t worsick                  \t 0.2668\n","file_t3_Super_Resolution.jpg\t r                        \t 0.0001\n","file_t4_Super_Resolution.jpg\t loy                      \t 0.0027\n","file_test-now-e_Super_Resolution.jpg\t basos                    \t 0.0027\n"]}]},{"cell_type":"code","source":["!python3 demo.py --Transformation None --FeatureExtraction VGG --SequenceModeling BiLSTM --Prediction CTC --image_folder demo_image/ --saved_model /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-VGG-BiLSTM-CTC.pth"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VfZzRf2A9ps7","executionInfo":{"status":"ok","timestamp":1679719779006,"user_tz":-330,"elapsed":4551,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"}},"outputId":"022c1525-e510-47da-a086-c5aab5049cb5"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","No Transformation module specified\n","model input parameters 32 100 20 1 512 256 37 25 None VGG BiLSTM CTC\n","loading pretrained model from /gdrive/MyDrive/CRAFT-OCR/CRAFT-pytorch/None-VGG-BiLSTM-CTC.pth\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","--------------------------------------------------------------------------------\n","image_path               \t predicted_labels         \t confidence score\n","--------------------------------------------------------------------------------\n","Cars0.png                \t ad                       \t 0.0011\n","Cars2.png                \t preatr                   \t 0.0301\n","Cars2_Super_Resolution.jpg\t preanep                  \t 0.0175\n","Cars18.png               \t msg6yob                  \t 0.1688\n","Cars20.png               \t and                      \t 0.0311\n","Cars21.png               \t itroes                   \t 0.0000\n","Cars21_Super_Resolution.jpg\t iro                      \t 0.0000\n","Cars181.png              \t shhad                    \t 0.0004\n","Cars181_Super_Resolution.jpg\t shhad                    \t 0.0006\n","Cars183.png              \t britooos                 \t 0.1082\n","Cars186.png              \t e2gspeal                 \t 0.0150\n","Cars190.png              \t kleaa2610                \t 0.0752\n","Cars193.png              \t beovsm                   \t 0.0134\n","Cars196.png              \t cns                      \t 0.0000\n","Cars197.png              \t alrbbtee                 \t 0.0734\n","Cars199.png              \t emhotaesoiz              \t 0.0925\n","Cars200.png              \t casss                    \t 0.0000\n","Cars201.png              \t alrbatee                 \t 0.0844\n","Cars202.png              \t kwid                     \t 0.2891\n","Cars206.png              \t creeuosed                \t 0.0001\n","file_Cars11.jpg          \t worsiek                  \t 0.4363\n","file_t3_Super_Resolution.jpg\t got                      \t 0.0021\n","file_t4_Super_Resolution.jpg\t lucnd                    \t 0.0003\n","file_test-now-e_Super_Resolution.jpg\t lateos                   \t 0.0003\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7872,"status":"ok","timestamp":1679708671011,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"JE7EL0TYl8by","outputId":"737c721e-b092-42b0-df3a-2b9415a42ca9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting lmdb\n","  Downloading lmdb-1.4.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (305 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.9/305.9 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (8.4.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n","Requirement already satisfied: natsort in /usr/local/lib/python3.9/dist-packages (5.5.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torchvision) (4.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.13.1+cu116)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n","Installing collected packages: lmdb\n","Successfully installed lmdb-1.4.0\n"]}],"source":["!pip3 install lmdb pillow torchvision nltk natsort"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":800,"status":"ok","timestamp":1679664993422,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"fGilzCK-maL_","outputId":"86e4977f-2f5a-4830-92dd-feb39111db8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Traceback (most recent call last):\n","  File \"/gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/create_lmdb_dataset.py\", line 87, in <module>\n","    fire.Fire(createDataset)\n","  File \"/usr/local/lib/python3.9/dist-packages/fire/core.py\", line 141, in Fire\n","    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n","  File \"/usr/local/lib/python3.9/dist-packages/fire/core.py\", line 475, in _Fire\n","    component, remaining_args = _CallAndUpdateTrace(\n","  File \"/usr/local/lib/python3.9/dist-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n","    component = fn(*varargs, **kwargs)\n","  File \"/gdrive/MyDrive/CRAFT-OCR/deep-text-recognition-benchmark/create_lmdb_dataset.py\", line 47, in createDataset\n","    imagePath, label = datalist[i].strip('\\n').split('\\t')\n","ValueError: not enough values to unpack (expected 2, got 1)\n"]}],"source":["!python3 create_lmdb_dataset.py --inputPath dataset_ocr/ --gtFile dataset_ocr/gt.txt --outputPath ocr_result/"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4708,"status":"ok","timestamp":1679685495813,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"},"user_tz":-330},"id":"N6oal4yL0OLq","outputId":"b38e9cd1-454b-4a3d-ff02-82e57dcce799"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fire in /usr/local/lib/python3.9/dist-packages (0.5.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from fire) (2.2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from fire) (1.16.0)\n"]}],"source":["!pip3 install fire"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7cQ7fFIw0QrU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1679708835784,"user_tz":-330,"elapsed":53314,"user":{"displayName":"Sakthi Genius","userId":"12049383565176758074"}},"outputId":"be40c1ce-b370-400f-8aba-112ae094f6a1"},"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n","  warnings.warn(\"Can't initialize NVML\")\n","Filtering the images containing characters which are not in opt.character\n","Filtering the images whose label is longer than opt.batch_max_length\n","--------------------------------------------------------------------------------\n","dataset_root: ocr_result/\n","opt.select_data: ['/']\n","opt.batch_ratio: ['1']\n","--------------------------------------------------------------------------------\n","dataset_root:    ocr_result/\t dataset: /\n","['/']  ** \n","sub-directory:\t/sec1\t num samples: 14\n","sub-directory:\t/sec2\t num samples: 14\n","num total samples of /: 28 x 1.0 (total_data_usage_ratio) = 28\n","num samples of / per batch: 28 x 1.0 (batch_ratio) = 28\n","/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","--------------------------------------------------------------------------------\n","Total_batch_size: 28 = 28\n","--------------------------------------------------------------------------------\n","dataset_root:    ocr_result/\t dataset: /\n","/  ** \n","sub-directory:\t/sec1\t num samples: 14\n","sub-directory:\t/sec2\t num samples: 14\n","--------------------------------------------------------------------------------\n","model input parameters 32 100 20 1 512 256 38 25 TPS ResNet BiLSTM Attn\n","Skip Transformation.LocalizationNetwork.localization_fc2.weight as it is already initialized\n","Skip Transformation.LocalizationNetwork.localization_fc2.bias as it is already initialized\n","Model:\n","DataParallel(\n","  (module): Model(\n","    (Transformation): TPS_SpatialTransformerNetwork(\n","      (LocalizationNetwork): LocalizationNetwork(\n","        (conv): Sequential(\n","          (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","          (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","          (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (6): ReLU(inplace=True)\n","          (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","          (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (10): ReLU(inplace=True)\n","          (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","          (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (14): ReLU(inplace=True)\n","          (15): AdaptiveAvgPool2d(output_size=1)\n","        )\n","        (localization_fc1): Sequential(\n","          (0): Linear(in_features=512, out_features=256, bias=True)\n","          (1): ReLU(inplace=True)\n","        )\n","        (localization_fc2): Linear(in_features=256, out_features=40, bias=True)\n","      )\n","      (GridGenerator): GridGenerator()\n","    )\n","    (FeatureExtraction): ResNet_FeatureExtractor(\n","      (ConvNet): ResNet(\n","        (conv0_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn0_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv0_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn0_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (layer1): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (downsample): Sequential(\n","              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","        )\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","        (layer2): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (downsample): Sequential(\n","              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","        )\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (maxpool3): MaxPool2d(kernel_size=2, stride=(2, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n","        (layer3): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","            (downsample): Sequential(\n","              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            )\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (3): BasicBlock(\n","            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (4): BasicBlock(\n","            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","        )\n","        (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (layer4): Sequential(\n","          (0): BasicBlock(\n","            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (1): BasicBlock(\n","            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","          (2): BasicBlock(\n","            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","            (relu): ReLU(inplace=True)\n","          )\n","        )\n","        (conv4_1): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 1), padding=(0, 1), bias=False)\n","        (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (conv4_2): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1), bias=False)\n","        (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n","    (SequenceModeling): Sequential(\n","      (0): BidirectionalLSTM(\n","        (rnn): LSTM(512, 256, batch_first=True, bidirectional=True)\n","        (linear): Linear(in_features=512, out_features=256, bias=True)\n","      )\n","      (1): BidirectionalLSTM(\n","        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n","        (linear): Linear(in_features=512, out_features=256, bias=True)\n","      )\n","    )\n","    (Prediction): Attention(\n","      (attention_cell): AttentionCell(\n","        (i2h): Linear(in_features=256, out_features=256, bias=False)\n","        (h2h): Linear(in_features=256, out_features=256, bias=True)\n","        (score): Linear(in_features=256, out_features=1, bias=False)\n","        (rnn): LSTMCell(294, 256)\n","      )\n","      (generator): Linear(in_features=256, out_features=38, bias=True)\n","    )\n","  )\n",")\n","Trainable params num :  49555182\n","Optimizer:\n","Adadelta (\n","Parameter Group 0\n","    eps: 1e-08\n","    foreach: None\n","    lr: 1\n","    maximize: False\n","    rho: 0.95\n","    weight_decay: 0\n",")\n","------------ Options -------------\n","exp_name: TPS-ResNet-BiLSTM-Attn-Seed1111\n","train_data: ocr_result/\n","valid_data: ocr_result/\n","manualSeed: 1111\n","workers: 4\n","batch_size: 28\n","num_iter: 2\n","valInterval: 2000\n","saved_model: \n","FT: True\n","adam: False\n","lr: 1\n","beta1: 0.9\n","rho: 0.95\n","eps: 1e-08\n","grad_clip: 5\n","baiduCTC: False\n","select_data: ['/']\n","batch_ratio: ['1']\n","total_data_usage_ratio: 1.0\n","batch_max_length: 25\n","imgH: 32\n","imgW: 100\n","rgb: False\n","character: 0123456789abcdefghijklmnopqrstuvwxyz\n","sensitive: False\n","PAD: False\n","data_filtering_off: False\n","Transformation: TPS\n","FeatureExtraction: ResNet\n","SequenceModeling: BiLSTM\n","Prediction: Attn\n","num_fiducial: 20\n","input_channel: 1\n","output_channel: 512\n","hidden_size: 256\n","num_gpu: 0\n","num_class: 38\n","---------------------------------------\n","\n","[1/2] Train loss: 3.65777, Valid loss: 3.62842, Elapsed_time: 17.56199\n","Current_accuracy : 0.000, Current_norm_ED  : 0.03\n","Best_accuracy    : 0.000, Best_norm_ED     : 0.03\n","--------------------------------------------------------------------------------\n","Ground Truth              | Prediction                | Confidence Score & T/F\n","--------------------------------------------------------------------------------\n","brit0001                  | kkk0000000000k000000xxxxx | 0.0000\tFalse\n","lr33tee                   | kkkkkkkkkkkkkkkkkkkkkkkkk | 0.0000\tFalse\n","prenup                    | kkkkkkkkkkkkkkkkkkkkkkkkk | 0.0000\tFalse\n","jh11had                   | k22222222222222222222kkkk | 0.0000\tFalse\n","ka22                      | kk22777777777777777777777 | 0.0000\tFalse\n","--------------------------------------------------------------------------------\n","end the training\n"]}],"source":["!python3 train.py \\\n","--train_data ocr_result/ --valid_data ocr_result/ \\\n","--select_data \"/\" --batch_ratio \"1\" \\\n","--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n","--batch_size \"28\" --num_iter 2 --FT"]},{"cell_type":"code","source":["!python3 demo.py \\\n","--Transformation TPS --FeatureExtraction ResNet --SequenceModeling BiLSTM --Prediction Attn \\\n","--image_folder demo_image/ \\\n","--saved_model TPS-ResNet-BiLSTM-Attn.pth"],"metadata":{"id":"oOXuopv1G2jA"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}